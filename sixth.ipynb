{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to Install Nvidia Drivers on Ubuntu 18.04\n",
    "\n",
    "# 1. ubuntu-drivers devices\n",
    "# 2. Download Nvidia Graphics Card Driver\n",
    "###    build-essential 같은 경우는 리처드 스톨만이 만든 소프트웨어 개발 툴들임\n",
    "###    gcc - C 컴파일러, g++ - C++, gcj - 자바, gdb - 디버거,\n",
    "###    binutils - 어셈블러, 링커, cmake, make는 빌드 자동화 도구\n",
    "# 3. sudo apt-get install build-essential\n",
    "###    (gcc, gdb, g++, gcj, binutils, cmake, make 같은\n",
    "###     개발 필수 소프트웨어 자동 설치)\n",
    "###    부팅할 때 디바이스 드라이버를 모듈 형식으로 삽입한다.\n",
    "###    이때 블랙리스트 처리할 장치를 설정하는 작업\n",
    "###    ACPI - 전원 관리 모듈(디바이스 드라이버)\n",
    "###    nouveau는 리눅스에 해킹을 통해서 만든 디바이스 드라이버(모니터용)\n",
    "###    제조사가 만든 장치의 전압과 전류 차이로 컴퓨터가 오동작하는 것을 방지!\n",
    "# 4. sudo bash -c \"echo blacklist nouveau > /etc/modprobe.d/blacklist-nvidia-nouveau.conf\"\n",
    "#    sudo bash -c \"echo options nouveau modeset=0 >> /etc/modprobe.d/blacklist-nvidia-nouveau.conf\"\n",
    "# 5. cat /etc/modprobe.d/blacklist-nvidia-nouveau.conf\n",
    "###    운영체제의 ram File System을 업데이트해서\n",
    "###    사용하는 펌웨어 및 드라이버 이미지를 갱신해준다.\n",
    "# 6. sudo update-initramfs -u\n",
    "# 7. sudo reboot\n",
    "###    그래픽 드라이버를 설치하므로 그래픽 드라이버 사용을 중지하기 위한 과정\n",
    "###    순수하게 터미널 작업만 하게 된다.\n",
    "# 8. ctrl + alt + F2 or F3 .... F8\n",
    "# 9. 로그인해야 한다 - id: bitai, pw - 456123\n",
    "#    시간초 제한이 있으므로 최대한 빠르게 입력해야 처리됨\n",
    "###     현재 구동중인 그래픽 드라이버를 정지\n",
    "# 10. sudo /etc/init.d/lightdm stop\n",
    "###     리눅스 런 레벨을 3 으로 강제한다(네트워킹, 그래픽 x, 터미널)\n",
    "# 11. sudo telinit 3\n",
    "### 실행 권한을 줘야 한다.\n",
    "# 12. cd ~/Downloads 혹은 cd ~/sw\n",
    "# 13. chmod +x NVIDIA-Linux-x86_64-440.100.run\n",
    "### 첫 번째 실행을 해본다.\n",
    "# 14. sudo ./NVIDIA-Linux-x86_64-440.100.run\n",
    "### 에러 메시지를 파악하는 과정(컴퓨터마다 다름)\n",
    "### Intel의 32비트 시스템에 대한 하위 호환을 지원해줌\n",
    "# 15. sudo dpkg --add-architecture i386\n",
    "### 위의 32비트 하위 호환을 적용한 소프트웨어를 업데이트할 수 있게 된다.\n",
    "# 16. sudo apt-get update\n",
    "### 32비트 호환 C Library를 설치한다.\n",
    "# 17. sudo apt-get install libc6:i386\n",
    "### Intel Xeon 버전이라 추가로 설치해야하는 SW가 존재한다.\n",
    "# 18. sudo apt-get install libglvnd-dev\n",
    "# 19. sudo apt-get install libncurses5-dev\n",
    "### BIOS Secure Boot 기능을 해제하는 것이 여러모로 편하다.\n",
    "### 현재 만약 Secure Boot가 해제가 안되었다면\n",
    "### Secure Boot 해제후 sudo telinit 3 을 반드시 다시 해줘야 한다.\n",
    "# 20. sudo ./NVIDIA-Linux-x86_64-440.100.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) TensorFlow 일반 버전(CPU)를 사용하는 버전\n",
    "# (2) TensorFlow GPU 버전이 별도로 존재한다(그래픽 카드 기반 가속)\n",
    "# (3) Vitis AI TensorFlow - FPGA 버전\n",
    "# CUDA(2)라는 Nvidia GPU HW 가속 라이브러리가 필요함!\n",
    "\n",
    "# 1. 우선 구글에서 Nvidia CUDA라고 검색한다.\n",
    "# 2. wget http://developer.download.nvidia.com/compute/cuda/11.0.1/local_installers/cuda_11.0.1_450.36.06_linux.run\n",
    "# 3. chmod +x cuda_11.0.1_450.36.06_linux.run\n",
    "### CUDA가 디바이스 드라이버의 기능을 활용하기 때문에\n",
    "### 해당 정보를 CUDA 소프트웨어가 알 필요성이 있기 때문에\n",
    "### 입력하는 명령어에 해당한다.\n",
    "# 4. sudo apt-get install linux-headers-$(uname -r)\n",
    "# 5. sudo ./cuda_11.0.1_450.36.06_linux.run\n",
    "# 6. 설치가 완료된 이후에 vi ~/.bashrc를 연다.\n",
    "#    맨 밑에 아래의 쉘 스크립트를 작성하도록 한다.\n",
    "#    export PATH=$PATH:/usr/local/cuda-11.0/bin\n",
    "### 변경 사항 적용!\n",
    "# 7. source ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nvidia Driver Check 명령어\n",
    "# 1. nvidia-smi\n",
    "### cuDNN을 설치하기 위해 cuDNN 검색\n",
    "# 2. https://developer.nvidia.com/cudnn으로 이동\n",
    "### 회원가입 및 라이센스 동의하고 cuDNN Library for Linux (x86)을 다운로드\n",
    "# 3. 다운 받은 내용을 압축해제한다.\n",
    "#    tar -zxvf cudnn-11.0-linux-x64-v8.0.1.13.tgz\n",
    "# 4. sudo vi /etc/ld.so.conf.d/cuda-11-0.conf\n",
    "#    아래의 두 개 내용을 기록해준다.\n",
    "#    /usr/local/cuda-11.0/targets/x86_64-linux/lib\n",
    "#    /usr/local/cuda-11.0/lib64\n",
    "# 4. sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/\n",
    "#    sudo cp cuda/include/cudnn.h /usr/local/cuda/include/\n",
    "#    sudo cp cuda/lib64/libcudnn* /usr/local/cuda-11.0/lib64/\n",
    "#    sudo cp cuda/include/cudnn.h /usr/local/cuda-11.0/include/\n",
    "# 5. 권한을 부여한다.\n",
    "#    sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\n",
    "#    sudo chmod a+r /usr/local/cuda-11.0/include/cudnn.h /usr/local/cuda-11.0/lib64/libcudnn*\n",
    "# 6. sudo apt-get install libcupti-dev\n",
    "# 7. pip3 install tensorflow-gpu  # 컴퓨터마다 다를 수 있음\n",
    "#    pip install tensorflow-gpu   # 아나콘다 경로로 작업해야함\n",
    "\n",
    "# 만약 pip가 안먹으면 아나콘다 설정이 날아간 것이다.\n",
    "# 아래 내용을 그대로 땡겨다가 ~/.bashrc 맨 아래쪽에 복사붙여넣기한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__conda_setup=\"$('/home/bitai/anaconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\"\n",
    "if [ $? -eq 0 ]; then\n",
    "    eval \"$__conda_setup\"\n",
    "else\n",
    "    if [ -f \"/home/bitai/anaconda3/etc/profile.d/conda.sh\" ]; then\n",
    "        . \"/home/bitai/anaconda3/etc/profile.d/conda.sh\"\n",
    "    else\n",
    "        export PATH=\"/home/bitai/anaconda3/bin:$PATH\"\n",
    "    fi\n",
    "fi\n",
    "unset __conda_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 814794961526074448,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11239367205578341596\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 5595094722316160787\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로세스와 스레드\n",
    "# 윈도우 vs 리눅스, 유닉스\n",
    "# 윈도우는 프로세스내에서 스레드가 쪼개지는 개념\n",
    "\n",
    "# 리눅스에서는 프로세스와 스레드가 모두 개별적인 Task 구조를 가진다.\n",
    "# Thread ID가 있어서 Thread ID 묶여있는 녀석들은 전부\n",
    "# 메모리 섹션의 Data 영역을 공유하게 된다.\n",
    "\n",
    "# 보통 스레드는 CPU 코어의 개수만큼 만들게 된다\n",
    "# (특정 하나의 연산을 극대화하고자 할 때)\n",
    "\n",
    "# 시나리오.\n",
    "# 스레드 A vs 스레드 B\n",
    "# 전역변수 D를 공통적으로 공유하고 있는 상태 <<< Critical Section(크리티컬 섹션)\n",
    "# 스레드 A가 하는 일은 ++\n",
    "# 스레드 B가 하는 일은 --\n",
    "# 프로세스란 CPU의 추상화다!\n",
    "# 우리가 구동하는 모든 프로그램은 CPU에게 제어권이 넘어가야만 실행이 가능하다.\n",
    "# 컴퓨터 구조론에서 제일 강조하는 것중 하나!\n",
    "# CPU는 오직 한 순간에 한 가지 일만 한다.\n",
    "# ???? 이게 왜 가능하지 ????\n",
    "# (1) Multi Tasking\n",
    "# (2) Context Switching\n",
    "\n",
    "# 위의 크리티컬 섹션이 된 녀석들의 데이터를\n",
    "# 안정적으로 보장해주기 위해 필요한 것이\n",
    "# 바로 Semaphore, Mutex, Spinlock 같은 녀석들이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU 스펙 보기\n",
    "# cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내일 할 것들\n",
    "# 1. Multi Tasking - 이론\n",
    "# 2. Context Switching - 이론\n",
    "# 3. Semaphore vs Spinlock - 실습\n",
    "# 4. 멀티 스레드 및 프로세스 vs 일반 작업의 성능 테스트\n",
    "\n",
    "# 1, 2번 설명 2 ~ 3 시간\n",
    "# 3 번은 실습만 끝날때까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(thread_0 ) Waiting to join the pool\n",
      "(thread_1 ) Waiting to join the pool\n",
      "(thread_2 ) Waiting to join the pool\n",
      "(thread_3 ) Waiting to join the pool\n",
      "(thread_4 ) Waiting to join the pool\n",
      "(thread_5 ) Waiting to join the pool\n",
      "(thread_6 ) Waiting to join the pool\n",
      "(thread_7 ) Waiting to join the pool\n",
      "(thread_8 ) Waiting to join the pool\n",
      "(thread_9 ) Waiting to join the pool\n",
      "(thread_0 ) Running: ['thread_0']\n",
      "(thread_1 ) Running: ['thread_0', 'thread_1']\n",
      "(thread_2 ) Running: ['thread_0', 'thread_1', 'thread_2']\n",
      "(thread_0 ) Running: ['thread_1', 'thread_2']\n",
      "(thread_1 ) Running: ['thread_2']\n",
      "(thread_3 ) Running: ['thread_2', 'thread_3']\n",
      "(thread_4 ) Running: ['thread_2', 'thread_3', 'thread_4']\n",
      "(thread_2 ) Running: ['thread_3', 'thread_4']\n",
      "(thread_3 ) Running: ['thread_4']\n",
      "(thread_5 ) Running: ['thread_4', 'thread_5']\n",
      "(thread_6 ) Running: ['thread_4', 'thread_5', 'thread_6']\n",
      "(thread_4 ) Running: ['thread_5', 'thread_6']\n",
      "(thread_5 ) Running: ['thread_6']\n",
      "(thread_7 ) Running: ['thread_6', 'thread_7']\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-9s) %(message)s',)\n",
    "\n",
    "class ThreadPool(object):\n",
    "    def __init__(self):\n",
    "        super(ThreadPool, self).__init__()\n",
    "        self.active = []\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "    def makeActive(self, name):\n",
    "        with self.lock:\n",
    "            self.active.append(name)\n",
    "\n",
    "            time.sleep(5)\n",
    "            logging.debug('Running: %s', self.active)\n",
    "    def makeInactive(self, name):\n",
    "        with self.lock:\n",
    "            self.active.remove(name)\n",
    "            logging.debug('Running: %s', self.active)\n",
    "\n",
    "def f(s, pool):\n",
    "    logging.debug('Waiting to join the pool')\n",
    "    with s:\n",
    "        name = threading.currentThread().getName()\n",
    "        pool.makeActive(name)\n",
    "        time.sleep(1)\n",
    "        pool.makeInactive(name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = ThreadPool()\n",
    "    s = threading.Semaphore(3)\n",
    "    for i in range(10):\n",
    "        t = threading.Thread(target=f, name='thread_'+str(i), args=(s, pool))\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
